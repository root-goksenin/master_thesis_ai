#!/bin/bash

#SBATCH --partition=gpu
#SBATCH --gpus=1
#SBATCH --job-name=CheckGPL
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=18
#SBATCH --time=04:00:00
#SBATCH --output=slurm_output_%A.out


module load 2022
module load Anaconda3/2022.05 
source activate gpl_env_1
cd $HOME/master_thesis_ai/gpl
export dataset_path=$HOME/master_thesis_ai/gpl/fiqa
export dataset=fiqa
srun python -m gpl.train     --gpl_steps 20000 --path_to_generated_data "$HOME/master_thesis_ai/generated/$dataset"     --base_ckpt "distilbert-base-uncased"     --gpl_score_function "dot"     --batch_size_gpl 32     --gpl_steps 140000     --new_size -1     --queries_per_passage -1     --output_dir "$HOME/master_thesis_ai/output/$dataset"     --evaluation_data "$dataset_path"     --evaluation_output "$HOME/master_thesis_ai/evaluation/$dataset"     --generator "BeIR/query-gen-msmarco-t5-base-v1"     --retrievers "msmarco-distilbert-base-v3" "msmarco-MiniLM-L-6-v3"     --retriever_score_functions "cos_sim" "cos_sim"     --cross_encoder "cross-encoder/ms-marco-MiniLM-L-6-v2"     --qgen_prefix "qgen"     --do_evaluation 
